{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "ratings = pd.read_table('models/data/bookcrossing/ratings.csv', sep=',', header=None, names=['UserId','ItemId','Rating'], engine='python')\n",
    "ratings = ratings.drop(0).reset_index(drop=True)\n",
    "ratings = ratings.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Rating to Count and drop Timestamp if it exists\n",
    "ratings = ratings.rename(columns={'Rating': 'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163094, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(ratings, test_size=.2, random_state=12)\n",
    "users_train = set(train.UserId)\n",
    "items_train = set(train.ItemId)\n",
    "test = test.loc[test.UserId.isin(users_train) & test.ItemId.isin(items_train)].reset_index(drop=True)\n",
    "del users_train, items_train\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "Hierarchical Poisson Factorization\n",
      "**********************************\n",
      "\n",
      "\n",
      "Saving user and item mappings...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/call/anaconda3/envs/workshop/lib/python3.11/site-packages/hpfrec/__init__.py:469: UserWarning: 'counts_df' contains observations with a count value less than 1, these will be ignored. Any user or item associated exclusively with zero-value observations will be excluded. If using 'reindex=False', make sure that your data still meets the necessary criteria. If you still want to use these observations, set 'stop_crit' to 'diff-norm' or 'maxiter'.\n",
      "  warnings.warn(\n",
      "/Users/call/anaconda3/envs/workshop/lib/python3.11/site-packages/hpfrec/__init__.py:478: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.input_df[\"UserId\"], self.user_mapping_ = pd.factorize(self.input_df[\"UserId\"])\n",
      "/Users/call/anaconda3/envs/workshop/lib/python3.11/site-packages/hpfrec/__init__.py:479: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.input_df[\"ItemId\"], self.item_mapping_ = pd.factorize(self.input_df[\"ItemId\"])\n",
      "/Users/call/anaconda3/envs/workshop/lib/python3.11/site-packages/hpfrec/__init__.py:510: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.input_df['Count'] = self.input_df[\"Count\"].astype(cython_loops.c_real_t)\n",
      "/Users/call/anaconda3/envs/workshop/lib/python3.11/site-packages/hpfrec/__init__.py:512: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.input_df['UserId'] = self.input_df[\"UserId\"].astype(cython_loops.obj_ind_type)\n",
      "/Users/call/anaconda3/envs/workshop/lib/python3.11/site-packages/hpfrec/__init__.py:514: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.input_df['ItemId'] = self.input_df[\"ItemId\"].astype(cython_loops.obj_ind_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 59842\n",
      "Number of items: 129060\n",
      "Latent factors to use: 50\n",
      "\n",
      "Initializing parameters...\n",
      "Allocating Phi matrix...\n",
      "Initializing optimization procedure...\n",
      "Iteration 10 | train llk: -12653290 | train rmse: 7.7435\n",
      "Iteration 20 | train llk: -11417208 | train rmse: 7.6831\n",
      "Iteration 30 | train llk: -11351700 | train rmse: 7.6799\n",
      "Iteration 40 | train llk: -11334521 | train rmse: 7.6803\n",
      "Iteration 50 | train llk: -11325954 | train rmse: 7.6805\n",
      "Iteration 60 | train llk: -11321549 | train rmse: 7.6803\n",
      "Iteration 70 | train llk: -11318207 | train rmse: 7.6802\n",
      "Iteration 80 | train llk: -11316044 | train rmse: 7.6802\n",
      "Iteration 90 | train llk: -11314566 | train rmse: 7.6801\n",
      "Iteration 100 | train llk: -11313452 | train rmse: 7.6801\n",
      "Iteration 110 | train llk: -11312549 | train rmse: 7.6800\n",
      "Iteration 120 | train llk: -11312130 | train rmse: 7.6800\n",
      "Iteration 130 | train llk: -11311544 | train rmse: 7.6800\n",
      "Iteration 140 | train llk: -11311011 | train rmse: 7.6800\n",
      "Iteration 150 | train llk: -11310672 | train rmse: 7.6800\n",
      "\n",
      "\n",
      "Optimization finished\n",
      "Final log-likelihood: -11310672\n",
      "Final RMSE: 7.6800\n",
      "Minutes taken (optimization part): 1.9\n",
      "\n",
      "Saving final parameters to .csv files...\n",
      "CPU times: user 6min 54s, sys: 13.7 s, total: 7min 8s\n",
      "Wall time: 2min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hpfrec.HPF at 0x16c0b91d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from hpfrec import HPF\n",
    "\n",
    "recommender = HPF(k=50, full_llk=False, random_seed=123,\n",
    "                  check_every=10, maxiter=150, reindex=True,\n",
    "                  allow_inconsistent_math=False,\n",
    "                  save_folder='models/parameters_dump_bc_50/')\n",
    "recommender.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12)\n",
    "sampled_users = rng.choice(test.UserId.unique(), size=1200, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_users = test.UserId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique item IDs\n",
    "items = ratings.ItemId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict ratings for the sample of users\n",
    "predictions = []\n",
    "for user in sampled_users:\n",
    "    user_predictions = []\n",
    "    for item in items:\n",
    "        user_predictions.append(recommender.predict(user=user, item=item))\n",
    "    predictions.append(user_predictions)\n",
    "predictions = np.array(predictions)\n",
    "#np.save(\"models/data/predictions/poisson_predictions_50.npy\", predictions)\n",
    "#np.save(\"models/data/predictions/poisson_test_users_50.npy\", sampled_users)\n",
    "np.save(\"poisson_predictions_bc_50.npy\", predictions)\n",
    "np.save(\"poisson_test_users_bc_50.npy\", sampled_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
